{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+qDV2ZtlF2XE8dOSfDvKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walkerjian/DailyCode/blob/main/LRUCacheC%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem:\n",
        "Implement an LRU (Least Recently Used) cache. It should be able to be initialized with a cache size n, and contain the following methods:\n",
        "\n",
        "set(key, value): sets key to value. If there are already n items in the cache and we are adding a new item, then it should also remove the least recently used item.\n",
        "get(key): gets the value at key. If no such key exists, return null.\n",
        "Each operation should run in O(1) time."
      ],
      "metadata": {
        "id": "W1_4RIQHzehB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Solution:\n",
        "Implementing an LRU (Least Recently Used) cache that has O(1) time complexity for both `set` and `get` operations can be achieved by combining a hash table with a double-ended queue (deque). In Python, we can use the `OrderedDict` from the `collections` module which maintains the order of insertion and can efficiently move items to the end.\n",
        "\n",
        "Here's a basic implementation of an LRU Cache in Python:\n",
        "\n",
        "```python\n",
        "from collections import OrderedDict\n",
        "\n",
        "class LRUCache:\n",
        "\n",
        "    def __init__(self, capacity: int):\n",
        "        self.cache = OrderedDict()\n",
        "        self.capacity = capacity\n",
        "\n",
        "    def get(self, key: int) -> int:\n",
        "        if key not in self.cache:\n",
        "            return None\n",
        "        else:\n",
        "            # Move the key to the end to show that it was recently used\n",
        "            self.cache.move_to_end(key, last=True)\n",
        "            return self.cache[key]\n",
        "\n",
        "    def set(self, key: int, value: int) -> None:\n",
        "        if key in self.cache:\n",
        "            # Move the key to the end to show that it was recently used\n",
        "            self.cache.move_to_end(key, last=True)\n",
        "        else:\n",
        "            if len(self.cache) >= self.capacity:\n",
        "                # Pop the first item (the least recently used)\n",
        "                self.cache.popitem(last=False)\n",
        "        self.cache[key] = value\n",
        "\n",
        "# Example usage:\n",
        "lru_cache = LRUCache(2)\n",
        "lru_cache.set(1, 1)  # cache is {1=1}\n",
        "lru_cache.set(2, 2)  # cache is {1=1, 2=2}\n",
        "print(lru_cache.get(1))    # returns 1\n",
        "lru_cache.set(3, 3)  # LRU key was 2, evicts key 2, cache is {1=1, 3=3}\n",
        "print(lru_cache.get(2))    # returns None (not found)\n",
        "lru_cache.set(4, 4)  # LRU key was 1, evicts key 1, cache is {4=4, 3=3}\n",
        "print(lru_cache.get(1))    # returns None (not found)\n",
        "print(lru_cache.get(3))    # returns 3\n",
        "print(lru_cache.get(4))    # returns 4\n",
        "```\n",
        "\n",
        "In the above implementation:\n",
        "\n",
        "- The `OrderedDict` will keep track of the order of insertion. When we access an item, we move it to the end of the `OrderedDict` to mark it as recently used. This operation is done in O(1) time.\n",
        "- When we need to set a new item, and the cache has reached its capacity, we remove the first item from the `OrderedDict`, which is the least recently used item. Again, this operation is done in O(1) time.\n",
        "- When we set an item that is already in the cache, we also move it to the end.\n",
        "- The `get` method returns the value for the given key if it exists in the cache, after moving the item to the end of the cache. If the key is not found, it returns `None`.\n",
        "\n",
        "This implementation will fulfill the requirements of having O(1) time complexity for both the `set` and `get` operations in the LRU cache."
      ],
      "metadata": {
        "id": "CPJdTclmzlDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementation:"
      ],
      "metadata": {
        "id": "CbFYl98XzqK1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDwBB_uxzc1e",
        "outputId": "9577c020-df0a-43ec-c5e1-779818bc0a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "None\n",
            "None\n",
            "3\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class LRUCache:\n",
        "\n",
        "    def __init__(self, capacity: int):\n",
        "        self.cache = OrderedDict()\n",
        "        self.capacity = capacity\n",
        "\n",
        "    def get(self, key: int) -> int:\n",
        "        if key not in self.cache:\n",
        "            return None\n",
        "        else:\n",
        "            # Move the key to the end to show that it was recently used\n",
        "            self.cache.move_to_end(key, last=True)\n",
        "            return self.cache[key]\n",
        "\n",
        "    def set(self, key: int, value: int) -> None:\n",
        "        if key in self.cache:\n",
        "            # Move the key to the end to show that it was recently used\n",
        "            self.cache.move_to_end(key, last=True)\n",
        "        else:\n",
        "            if len(self.cache) >= self.capacity:\n",
        "                # Pop the first item (the least recently used)\n",
        "                self.cache.popitem(last=False)\n",
        "        self.cache[key] = value\n",
        "\n",
        "# Example usage:\n",
        "lru_cache = LRUCache(2)\n",
        "lru_cache.set(1, 1)  # cache is {1=1}\n",
        "lru_cache.set(2, 2)  # cache is {1=1, 2=2}\n",
        "print(lru_cache.get(1))    # returns 1\n",
        "lru_cache.set(3, 3)  # LRU key was 2, evicts key 2, cache is {1=1, 3=3}\n",
        "print(lru_cache.get(2))    # returns None (not found)\n",
        "lru_cache.set(4, 4)  # LRU key was 1, evicts key 1, cache is {4=4, 3=3}\n",
        "print(lru_cache.get(1))    # returns None (not found)\n",
        "print(lru_cache.get(3))    # returns 3\n",
        "print(lru_cache.get(4))    # returns 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementing an LRU Cache in C++:\n",
        "Implementing an LRU Cache in C++ requires a combination of a hash table (such as `std::unordered_map`) and a doubly linked list to achieve O(1) time complexity for both `set` and `get` operations. However, unlike Python, C++'s standard library does not have an `OrderedDict` equivalent that allows O(1) access and update, so we need to implement this functionality manually.\n",
        "\n",
        "The toolkit approach means we will create separate components, and the MVC (Model-View-Controller) architecture will guide the structure, although it's somewhat unusual for such a data structure implementation. The \"model\" will be the LRU Cache itself, the \"view\" could hypothetically be a way to display cache status, and the \"controller\" will handle inputs and commands to the cache.\n",
        "\n",
        "Here's an outline for the LRU Cache in C++ using a toolkit approach:\n",
        "\n",
        "1. **Model**: `LRUCache` class\n",
        "2. **View**: Console output for displaying cache status (if needed, as this is not typical for such a low-level data structure)\n",
        "3. **Controller**: Interactions with the `LRUCache` instance\n",
        "4. **Test**: A simple test framework that runs various commands on the cache and reports any failures\n",
        "\n",
        "Let's start by defining the `LRUCache` class. In the interest of brevity, we'll focus on the key methods and data structures:"
      ],
      "metadata": {
        "id": "NcDVgCgNz17Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lru_cache.cpp\n",
        "#include <iostream>\n",
        "#include <unordered_map>\n",
        "#include <list>\n",
        "#include <cassert>\n",
        "\n",
        "/**\n",
        " * A node structure to store the key-value pairs that will be stored in the cache.\n",
        " */\n",
        "struct Node {\n",
        "    int key;\n",
        "    int value;\n",
        "    Node(int k, int v) : key(k), value(v) {}\n",
        "};\n",
        "\n",
        "/**\n",
        " * The LRUCache class implements an LRU (Least Recently Used) cache.\n",
        " * It supports operations to insert and retrieve values in O(1) time.\n",
        " */\n",
        "class LRUCache {\n",
        "private:\n",
        "    int capacity; // The capacity of the cache\n",
        "    // A list to represent the order of the cache items, with the most recently used at the back\n",
        "    std::list<Node> cacheItemsList;\n",
        "    // A hash map that maps keys to iterators in the cache list\n",
        "    std::unordered_map<int, std::list<Node>::iterator> cacheItemsMap;\n",
        "\n",
        "public:\n",
        "    /**\n",
        "     * Constructor for the LRUCache.\n",
        "     * @param capacity The maximum number of items that the cache can hold.\n",
        "     */\n",
        "    LRUCache(int capacity) : capacity(capacity) {}\n",
        "\n",
        "    /**\n",
        "     * Retrieves the value associated with a given key from the cache.\n",
        "     * If the key is not found, returns -1.\n",
        "     * @param key The key of the item to retrieve.\n",
        "     * @return The value associated with the key, or -1 if the key is not found.\n",
        "     */\n",
        "    int get(int key) {\n",
        "        auto it = cacheItemsMap.find(key);\n",
        "        if (it == cacheItemsMap.end()) {\n",
        "            // Key is not found in the cache\n",
        "            return -1; // Use -1 to indicate not found\n",
        "        }\n",
        "        // Move the accessed item to the end of the list to mark it as recently used\n",
        "        cacheItemsList.splice(cacheItemsList.end(), cacheItemsList, it->second);\n",
        "        return it->second->value;\n",
        "    }\n",
        "\n",
        "    /**\n",
        "     * Inserts a key-value pair into the cache. If the key already exists, updates the value.\n",
        "     * If the cache is full, it evicts the least recently used item before inserting the new item.\n",
        "     * @param key The key of the item to insert.\n",
        "     * @param value The value to associate with the key.\n",
        "     */\n",
        "    void set(int key, int value) {\n",
        "        auto it = cacheItemsMap.find(key);\n",
        "        if (it != cacheItemsMap.end()) {\n",
        "            // Item is found, update the value and move it to the end\n",
        "            it->second->value = value;\n",
        "            cacheItemsList.splice(cacheItemsList.end(), cacheItemsList, it->second);\n",
        "            return;\n",
        "        }\n",
        "        // Item is not found and the cache is full, so we need to evict the least recently used item\n",
        "        if (cacheItemsList.size() == capacity) {\n",
        "            // Remove the least recently used item\n",
        "            int keyToRemove = cacheItemsList.front().key;\n",
        "            cacheItemsMap.erase(keyToRemove);\n",
        "            cacheItemsList.pop_front();\n",
        "        }\n",
        "        // Insert the new item into the cache\n",
        "        cacheItemsList.emplace_back(key, value);\n",
        "        // Update the mapping from the key to the iterator in the list\n",
        "        auto listIt = --cacheItemsList.end();\n",
        "        cacheItemsMap[key] = listIt;\n",
        "    }\n",
        "};\n",
        "\n",
        "\n",
        "// Testing framework\n",
        "void runTests() {\n",
        "    LRUCache cache(2);\n",
        "\n",
        "    cache.set(1, 1);\n",
        "    assert(cache.get(1) == 1); // Test 1 passed\n",
        "\n",
        "    cache.set(2, 2);\n",
        "    assert(cache.get(2) == 2); // Test 2 passed\n",
        "\n",
        "    cache.set(3, 3);\n",
        "    assert(cache.get(1) == -1); // Test 3 passed, 1 should be evicted\n",
        "\n",
        "    cache.set(4, 4);\n",
        "    assert(cache.get(2) == -1); // Test 4 passed, 2 should be evicted\n",
        "\n",
        "    assert(cache.get(3) == 3); // Test 5 passed\n",
        "    assert(cache.get(4) == 4); // Test 6 passed\n",
        "\n",
        "    std::cout << \"All tests passed.\" << std::endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    runTests();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XClzDSVIz1kd",
        "outputId": "ac0d6d32-cd34-4f5b-d1fe-84c772a395fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lru_cache.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ lru_cache.cpp -o lru_cache -std=c++11"
      ],
      "metadata": {
        "id": "SCMunlvDzw3t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./lru_cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghg7hhkQ0fRk",
        "outputId": "947f9ba2-2a54-4cb4-86a5-d24b4bdd8e1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed.\n"
          ]
        }
      ]
    }
  ]
}