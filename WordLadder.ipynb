{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWXQ4mNwx+z6n+jOaQUxnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walkerjian/DailyCode/blob/main/WordLadder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpjgPz8bHwOr",
        "outputId": "b958bda4-6c16-4e87-9aa9-76d2252e7447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['COLD', 'WOLD', 'WORD', 'WARD', 'WARM']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "# Download the word list from NLTK\n",
        "nltk.download('words')\n",
        "from nltk.corpus import words\n",
        "\n",
        "# Convert the word list to uppercase to match the test words\n",
        "word_list = [word.upper() for word in words.words()]\n",
        "\n",
        "def construct_dict(word_list):\n",
        "    d = defaultdict(list)\n",
        "    for word in word_list:\n",
        "        for i in range(len(word)):\n",
        "            s = word[:i] + \"_\" + word[i+1:]\n",
        "            d[s].append(word)\n",
        "    return d\n",
        "\n",
        "def bfs_words(begin, end, lookup_dict):\n",
        "    queue, visited = deque([(begin, [begin])]), set()\n",
        "\n",
        "    while queue:\n",
        "        word, path = queue.popleft()\n",
        "        visited.add(word)\n",
        "        for i in range(len(word)):\n",
        "            s = word[:i] + \"_\" + word[i+1:]\n",
        "            neigh_words = lookup_dict[s]\n",
        "            for neigh in neigh_words:\n",
        "                if neigh not in visited:\n",
        "                    if neigh == end:\n",
        "                        return path + [neigh]\n",
        "                    else:\n",
        "                        queue.append((neigh, path + [neigh]))\n",
        "\n",
        "def generate_word_ladder(start_word, end_word, word_list):\n",
        "    lookup_dict = construct_dict(word_list)\n",
        "    return bfs_words(start_word, end_word, lookup_dict)\n",
        "\n",
        "# Now you can use the function with the test cases\n",
        "print(generate_word_ladder(\"COLD\", \"WARM\", word_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case 1: Single-letter change between words\n",
        "print(\"Test case 1: Single-letter change\")\n",
        "print(generate_word_ladder(\"CAT\", \"BAT\", word_list))\n",
        "\n",
        "# Test case 2: Multiple-letter changes needed\n",
        "print(\"\\nTest case 2: Multiple-letter changes needed\")\n",
        "print(generate_word_ladder(\"COLD\", \"WARM\", word_list))\n",
        "\n",
        "# Test case 3: Same starting and ending word\n",
        "print(\"\\nTest case 3: Same starting and ending word\")\n",
        "print(generate_word_ladder(\"DOG\", \"DOG\", word_list))\n",
        "\n",
        "# Test case 4: Impossible case\n",
        "print(\"\\nTest case 4: Impossible case\")\n",
        "print(generate_word_ladder(\"DOG\", \"CAT\", word_list))\n",
        "\n",
        "# Test case 5: Case insensitivity\n",
        "print(\"\\nTest case 5: Case insensitivity\")\n",
        "print(generate_word_ladder(\"Dog\", \"cat\", word_list))\n",
        "\n",
        "# Test case 6: Long words\n",
        "print(\"\\nTest case 6: Long words\")\n",
        "print(generate_word_ladder(\"INFORMATION\", \"COMPUTATION\", word_list))\n",
        "\n",
        "# Test case 7: Non-existent words\n",
        "print(\"\\nTest case 7: Non-existent words\")\n",
        "print(generate_word_ladder(\"INFO\", \"COMPU\", word_list))\n",
        "\n",
        "# Test case 8: Transition between words of different lengths\n",
        "print(\"\\nTest case 8: Transition between words of different lengths\")\n",
        "print(generate_word_ladder(\"I\", \"COMPUTATION\", word_list))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNRmebAuJjrr",
        "outputId": "cf01e0e5-d9b1-48d6-d0c9-ecf22e61c5be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test case 1: Single-letter change\n",
            "['CAT', 'BAT']\n",
            "\n",
            "Test case 2: Multiple-letter changes needed\n",
            "['COLD', 'WOLD', 'WORD', 'WARD', 'WARM']\n",
            "\n",
            "Test case 3: Same starting and ending word\n",
            "None\n",
            "\n",
            "Test case 4: Impossible case\n",
            "['DOG', 'COG', 'CAG', 'CAT']\n",
            "\n",
            "Test case 5: Case insensitivity\n",
            "None\n",
            "\n",
            "Test case 6: Long words\n",
            "None\n",
            "\n",
            "Test case 7: Non-existent words\n",
            "None\n",
            "\n",
            "Test case 8: Transition between words of different lengths\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}