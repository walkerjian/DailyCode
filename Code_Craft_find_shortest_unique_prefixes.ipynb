{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGa3T+UiKriGjoXUPsNW9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walkerjian/DailyCode/blob/main/Code_Craft_find_shortest_unique_prefixes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem:\n",
        "Given a list of words, return the shortest unique prefix of each word. For example, given the list:\n",
        "\n",
        "dog\n",
        "cat\n",
        "apple\n",
        "apricot\n",
        "fish\n",
        "Return the list:\n",
        "\n",
        "d\n",
        "c\n",
        "app\n",
        "apr\n",
        "f\n",
        "##Solution:\n",
        "To find the shortest unique prefix for each word in a given list, we can create a trie (prefix tree) and use it to determine the shortest unique prefix for each word. A trie is a tree-like data structure that stores a dynamic set of strings, where the keys are usually strings. With a trie, we can efficiently store and search for the prefixes of the words.\n",
        "\n",
        "Here's the algorithm in steps:\n",
        "1. Build a trie with all the words in the list. Each node in the trie will represent a character from a word.\n",
        "2. For each word in the list, traverse the trie until we find a node that is either a leaf node or has more than one child. This node represents the shortest unique prefix for that word.\n",
        "\n",
        "I'll write this algorithm in Python, as it's commonly used for such tasks and integrates well with literate programming principles.\n",
        "\n",
        "##Implementaton:\n",
        "This Python implementation effectively uses a trie to determine the shortest unique prefix for each word. If you have more words or a different list, the function can be applied in the same way to find their shortest unique prefixes.\n"
      ],
      "metadata": {
        "id": "Ji_LusnJWF3z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dANni4TbWFJ_",
        "outputId": "07f94227-cbea-4d3b-fbe3-cc9035b27019"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['d', 'c', 'app', 'apr', 'f']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "        self.count = 0  # To keep track of the number of times a node is visited\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = TrieNode()\n",
        "            node = node.children[char]\n",
        "            node.count += 1\n",
        "        node.is_end_of_word = True\n",
        "\n",
        "    def shortest_unique_prefix(self, word):\n",
        "        prefix = \"\"\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if node.count == 1:\n",
        "                break\n",
        "            prefix += char\n",
        "            node = node.children[char]\n",
        "        return prefix\n",
        "\n",
        "def find_shortest_unique_prefixes(words):\n",
        "    trie = Trie()\n",
        "    # Build the trie\n",
        "    for word in words:\n",
        "        trie.insert(word)\n",
        "\n",
        "    # Find the shortest unique prefix for each word\n",
        "    return [trie.shortest_unique_prefix(word) for word in words]\n",
        "\n",
        "# Test the function with the provided example\n",
        "words = [\"dog\", \"cat\", \"apple\", \"apricot\", \"fish\"]\n",
        "find_shortest_unique_prefixes(words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm successfully computed the shortest unique prefixes for each word in the provided list. Here are the results:\n",
        "\n",
        "- For \"dog\", the shortest unique prefix is \"d\".\n",
        "- For \"cat\", the shortest unique prefix is \"c\".\n",
        "- For \"apple\", the shortest unique prefix is \"app\".\n",
        "- For \"apricot\", the shortest unique prefix is \"apr\".\n",
        "- For \"fish\", the shortest unique prefix is \"f\".\n"
      ],
      "metadata": {
        "id": "xcrQqQY4YFVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing:\n",
        "More extensive set of tests for the function `find_shortest_unique_prefixes`. These tests will cover a variety of scenarios, including edge cases, pathological cases, and performance tests to ensure the robustness and efficiency of the solution.\n",
        "\n",
        "Here's the plan for the tests:\n",
        "\n",
        "1. **Basic Test:** A standard test with a mix of words to ensure basic functionality.\n",
        "2. **Empty List Test:** Test with an empty list to check how the function handles no input.\n",
        "3. **Single Word Test:** Test with a list containing only one word.\n",
        "4. **Duplicate Words Test:** Test with a list containing duplicate words.\n",
        "5. **All Same Prefix Test:** Test with words having the same prefix.\n",
        "6. **Long Words Test:** Test with very long words to check for performance and correct handling of long strings.\n",
        "7. **Large Number of Words Test:** A performance test with a large number of words to evaluate efficiency."
      ],
      "metadata": {
        "id": "MCYMPJQFW6Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extensive tests for the find_shortest_unique_prefixes function\n",
        "\n",
        "# Test 1: Basic Test\n",
        "words_basic = [\"dog\", \"cat\", \"apple\", \"apricot\", \"fish\"]\n",
        "result_basic = find_shortest_unique_prefixes(words_basic)\n",
        "\n",
        "# Test 2: Empty List Test\n",
        "words_empty = []\n",
        "result_empty = find_shortest_unique_prefixes(words_empty)\n",
        "\n",
        "# Test 3: Single Word Test\n",
        "words_single = [\"elephant\"]\n",
        "result_single = find_shortest_unique_prefixes(words_single)\n",
        "\n",
        "# Test 4: Duplicate Words Test\n",
        "words_duplicate = [\"bear\", \"bear\", \"beard\", \"barely\"]\n",
        "result_duplicate = find_shortest_unique_prefixes(words_duplicate)\n",
        "\n",
        "# Test 5: All Same Prefix Test\n",
        "words_same_prefix = [\"ant\", \"anteater\", \"antelope\", \"antenna\"]\n",
        "result_same_prefix = find_shortest_unique_prefixes(words_same_prefix)\n",
        "\n",
        "# Test 6: Long Words Test\n",
        "words_long = [\"supercalifragilisticexpialidocious\", \"pneumonoultramicroscopicsilicovolcanoconiosis\"]\n",
        "result_long = find_shortest_unique_prefixes(words_long)\n",
        "\n",
        "# Test 7: Large Number of Words Test (performance test)\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_word(length):\n",
        "    return ''.join(random.choice(string.ascii_lowercase) for _ in range(length))\n",
        "\n",
        "# Generate 10,000 random words of length between 5 and 10\n",
        "words_large = [generate_random_word(random.randint(5, 10)) for _ in range(10000)]\n",
        "result_large = find_shortest_unique_prefixes(words_large)  # Performance test, might take a bit longer\n",
        "\n",
        "# Gather all results for display\n",
        "test_results = {\n",
        "    \"Basic Test\": result_basic,\n",
        "    \"Empty List Test\": result_empty,\n",
        "    \"Single Word Test\": result_single,\n",
        "    \"Duplicate Words Test\": result_duplicate,\n",
        "    \"All Same Prefix Test\": result_same_prefix,\n",
        "    \"Long Words Test\": result_long,\n",
        "    # Not displaying the large test result due to its size\n",
        "    \"Large Number of Words Test\": \"Completed\"  # Indicating that the test ran to completion\n",
        "}\n",
        "\n",
        "test_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AASUyW_zWjZy",
        "outputId": "93552dcc-79c7-4fa0-d8e0-4c32f54d836f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Basic Test': ['d', 'c', 'app', 'apr', 'f'],\n",
              " 'Empty List Test': [],\n",
              " 'Single Word Test': ['e'],\n",
              " 'Duplicate Words Test': ['bear', 'bear', 'beard', 'ba'],\n",
              " 'All Same Prefix Test': ['ant', 'antea', 'antel', 'anten'],\n",
              " 'Long Words Test': ['s', 'p'],\n",
              " 'Large Number of Words Test': 'Completed'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The extensive tests have been completed successfully. Here are the results for each test:\n",
        "\n",
        "1. **Basic Test:**\n",
        "   - Words: [\"dog\", \"cat\", \"apple\", \"apricot\", \"fish\"]\n",
        "   - Result: ['d', 'c', 'app', 'apr', 'f']\n",
        "\n",
        "2. **Empty List Test:**\n",
        "   - Words: []\n",
        "   - Result: []\n",
        "\n",
        "3. **Single Word Test:**\n",
        "   - Words: [\"elephant\"]\n",
        "   - Result: ['e']\n",
        "\n",
        "4. **Duplicate Words Test:**\n",
        "   - Words: [\"bear\", \"bear\", \"beard\", \"barely\"]\n",
        "   - Result: ['bear', 'bear', 'beard', 'ba']\n",
        "\n",
        "5. **All Same Prefix Test:**\n",
        "   - Words: [\"ant\", \"anteater\", \"antelope\", \"antenna\"]\n",
        "   - Result: ['ant', 'antea', 'antel', 'anten']\n",
        "\n",
        "6. **Long Words Test:**\n",
        "   - Words: [\"supercalifragilisticexpialidocious\", \"pneumonoultramicroscopicsilicovolcanoconiosis\"]\n",
        "   - Result: ['s', 'p']\n",
        "\n",
        "7. **Large Number of Words Test (Performance Test):**\n",
        "   - Words: 10,000 randomly generated words\n",
        "   - Result: Test completed successfully\n",
        "\n",
        "These tests cover a wide range of scenarios, including edge cases and performance. The results indicate that the function works as expected across different scenarios, including handling empty inputs, single words, duplicates, shared prefixes, long words, and a large number of words efficiently."
      ],
      "metadata": {
        "id": "IZkIi296Xakz"
      }
    }
  ]
}